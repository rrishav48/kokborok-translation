{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7983d608-dafd-4efd-8d7f-c46a8777bbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 'exit' to quit the translator.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter an English sentence:  hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kokborok translation: Khulum\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter an English sentence:  hello thank you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kokborok translation: Khulum Bathwngthai\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter an English sentence:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye! ðŸ‘‹\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('kokdata2.csv')\n",
    "translation_dict = dict(zip(data['English'].str.lower(), data['Kokborok']))\n",
    "\n",
    "def translate_to_kokborok(sentence):\n",
    "    words = sentence.lower().split()  # Tokenize by space\n",
    "    translated_sentence = []\n",
    "    english_phrases = list(translation_dict.keys())\n",
    "\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        # Match 2-word phrase\n",
    "        if i + 1 < len(words):\n",
    "            two_word = f\"{words[i]} {words[i+1]}\"\n",
    "            if two_word in translation_dict:\n",
    "                translated_sentence.append(translation_dict[two_word])\n",
    "                i += 2\n",
    "                continue\n",
    "\n",
    "        # Match single word exactly\n",
    "        if words[i] in translation_dict:\n",
    "            translated_sentence.append(translation_dict[words[i]])\n",
    "        else:\n",
    "            # Optional: fuzzy fallback for single word typos\n",
    "            match, score = process.extractOne(words[i], english_phrases)\n",
    "            if score > 90:\n",
    "                translated_sentence.append(translation_dict[match])\n",
    "            else:\n",
    "                translated_sentence.append(f\"[{words[i]}]\")  # mark untranslated\n",
    "        i += 1\n",
    "\n",
    "    return ' '.join(translated_sentence)\n",
    "\n",
    "# Continuous input loop\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Type 'exit' to quit the translator.\")\n",
    "    while True:\n",
    "        user_input = input(\"\\nEnter an English sentence: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Goodbye! ðŸ‘‹\")\n",
    "            break\n",
    "        kokborok_translation = translate_to_kokborok(user_input)\n",
    "        print(f\"Kokborok translation: {kokborok_translation}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "213210a3-133e-4ccc-8f2f-5d0e86988c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 'exit' to quit the translator.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter an English sentence:  hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kokborok translation: Khulum\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter an English sentence:  hello?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kokborok translation: Khulum [?]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter an English sentence:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye! ðŸ‘‹\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('kokdata2.csv')\n",
    "data.columns = data.columns.str.strip()\n",
    "translation_dict = dict(zip(data['English'].str.lower(), data['Kokborok']))\n",
    "\n",
    "# Parameters\n",
    "FUZZY_THRESHOLD = 90\n",
    "\n",
    "# Preprocessing function\n",
    "def tokenize(text):\n",
    "    # Lowercase and handle punctuation\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'([.,!?])', r' \\1 ', text)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "    return text.strip().split()\n",
    "\n",
    "# Translator function\n",
    "def translate_to_kokborok(sentence):\n",
    "    words = tokenize(sentence)\n",
    "    translated_sentence = []\n",
    "    english_phrases = list(translation_dict.keys())\n",
    "\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        matched = False\n",
    "\n",
    "        # Try trigrams\n",
    "        if i + 2 < len(words):\n",
    "            trigram = f\"{words[i]} {words[i+1]} {words[i+2]}\"\n",
    "            if trigram in translation_dict:\n",
    "                translated_sentence.append(translation_dict[trigram])\n",
    "                i += 3\n",
    "                matched = True\n",
    "\n",
    "        # Try bigrams\n",
    "        if not matched and i + 1 < len(words):\n",
    "            bigram = f\"{words[i]} {words[i+1]}\"\n",
    "            if bigram in translation_dict:\n",
    "                translated_sentence.append(translation_dict[bigram])\n",
    "                i += 2\n",
    "                matched = True\n",
    "\n",
    "        # Try single word\n",
    "        if not matched:\n",
    "            word = words[i]\n",
    "            if word in translation_dict:\n",
    "                translated_sentence.append(translation_dict[word])\n",
    "            else:\n",
    "                match, score = process.extractOne(word, english_phrases)\n",
    "                if score >= FUZZY_THRESHOLD:\n",
    "                    translated_sentence.append(translation_dict[match])\n",
    "                else:\n",
    "                    translated_sentence.append(f\"[{word}]\")  # untranslated\n",
    "            i += 1\n",
    "\n",
    "    return ' '.join(translated_sentence)\n",
    "\n",
    "# Continuous input loop\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Type 'exit' to quit the translator.\")\n",
    "    while True:\n",
    "        user_input = input(\"\\nEnter an English sentence: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Goodbye! ðŸ‘‹\")\n",
    "            break\n",
    "        kokborok_translation = translate_to_kokborok(user_input)\n",
    "        print(f\"Kokborok translation: {kokborok_translation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5027b0f0-96f0-439f-8206-6098cc2b9c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Deep learning model not found, only dictionary/fuzzy matching will be used.\n",
      "Type 'exit' to quit the translator.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter an English sentence:  hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kokborok translation: Khulum\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter an English sentence:  hello?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kokborok translation: Khulum [UNK]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter an English sentence:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye! ðŸ‘‹\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from fuzzywuzzy import process\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('kokdata2.csv')\n",
    "data.columns = data.columns.str.strip()\n",
    "translation_dict = dict(zip(data['English'].str.lower(), data['Kokborok']))\n",
    "\n",
    "# Parameters\n",
    "FUZZY_THRESHOLD = 90\n",
    "MAX_SEQUENCE_LENGTH = 20\n",
    "\n",
    "# Load tokenizer and model (Assumes you saved tokenizer and model after training)\n",
    "tokenizer_eng = Tokenizer()\n",
    "tokenizer_kok = Tokenizer()\n",
    "\n",
    "# Fit tokenizer on dataset\n",
    "all_eng = data['English'].str.lower().tolist()\n",
    "all_kok = data['Kokborok'].str.lower().tolist()\n",
    "tokenizer_eng.fit_on_texts(all_eng)\n",
    "tokenizer_kok.fit_on_texts(all_kok)\n",
    "\n",
    "# Load pre-trained model (you must have this saved from training phase)\n",
    "try:\n",
    "    model = load_model('kokborok_seq2seq_model.h5')\n",
    "except:\n",
    "    model = None\n",
    "    print(\"Warning: Deep learning model not found, only dictionary/fuzzy matching will be used.\")\n",
    "\n",
    "# Preprocessing function\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'([.,!?])', r' \\1 ', text)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "    return text.strip().split()\n",
    "\n",
    "# Rule-based Translator\n",
    "def translate_with_dictionary(words):\n",
    "    translated_sentence = []\n",
    "    english_phrases = list(translation_dict.keys())\n",
    "\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        matched = False\n",
    "\n",
    "        if i + 2 < len(words):\n",
    "            trigram = f\"{words[i]} {words[i+1]} {words[i+2]}\"\n",
    "            if trigram in translation_dict:\n",
    "                translated_sentence.append(translation_dict[trigram])\n",
    "                i += 3\n",
    "                matched = True\n",
    "\n",
    "        if not matched and i + 1 < len(words):\n",
    "            bigram = f\"{words[i]} {words[i+1]}\"\n",
    "            if bigram in translation_dict:\n",
    "                translated_sentence.append(translation_dict[bigram])\n",
    "                i += 2\n",
    "                matched = True\n",
    "\n",
    "        if not matched:\n",
    "            word = words[i]\n",
    "            if word in translation_dict:\n",
    "                translated_sentence.append(translation_dict[word])\n",
    "            else:\n",
    "                match, score = process.extractOne(word, english_phrases)\n",
    "                if score >= FUZZY_THRESHOLD:\n",
    "                    translated_sentence.append(translation_dict[match])\n",
    "                else:\n",
    "                    translated_sentence.append(f\"[UNK]\")\n",
    "            i += 1\n",
    "\n",
    "    return translated_sentence\n",
    "\n",
    "# Deep Learning Translator\n",
    "def translate_with_model(sentence):\n",
    "    seq = tokenizer_eng.texts_to_sequences([sentence])\n",
    "    seq = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "    \n",
    "    prediction = model.predict(seq)\n",
    "    output_seq = np.argmax(prediction, axis=-1)\n",
    "    translated_tokens = tokenizer_kok.sequences_to_texts(output_seq)\n",
    "    return translated_tokens[0]\n",
    "\n",
    "# Main translator\n",
    "def hybrid_translate(sentence):\n",
    "    words = tokenize(sentence)\n",
    "    dict_translation = translate_with_dictionary(words)\n",
    "\n",
    "    # If too many [UNK], fallback to model\n",
    "    unk_count = dict_translation.count(\"[UNK]\")\n",
    "    if model and unk_count > len(words) * 0.3:  # fallback threshold\n",
    "        print(\"[INFO] Fallback to deep learning model.\")\n",
    "        return translate_with_model(sentence)\n",
    "    else:\n",
    "        return ' '.join(dict_translation)\n",
    "\n",
    "# Continuous input loop\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Type 'exit' to quit the translator.\")\n",
    "    while True:\n",
    "        user_input = input(\"\\nEnter an English sentence: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Goodbye! ðŸ‘‹\")\n",
    "            break\n",
    "        kokborok_translation = hybrid_translate(user_input)\n",
    "        print(f\"Kokborok translation: {kokborok_translation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71358b3-09dc-4288-ba31-90f35edf67fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Deep learning model not found, only dictionary/fuzzy matching will be used.\n",
      "Type 'exit' to quit the translator.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter an English sentence:  hello?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kokborok translation: Khulum ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter an English sentence:  hello thank you ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kokborok translation: Khulum Bathwngthai ?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from fuzzywuzzy import process\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('kokdata2.csv')\n",
    "data.columns = data.columns.str.strip()\n",
    "translation_dict = dict(zip(data['English'].str.lower(), data['Kokborok']))\n",
    "\n",
    "# Parameters\n",
    "FUZZY_THRESHOLD = 90\n",
    "MAX_SEQUENCE_LENGTH = 20\n",
    "\n",
    "# Load tokenizer and model (Assumes you saved tokenizer and model after training)\n",
    "tokenizer_eng = Tokenizer()\n",
    "tokenizer_kok = Tokenizer()\n",
    "\n",
    "# Fit tokenizer on dataset\n",
    "all_eng = data['English'].str.lower().tolist()\n",
    "all_kok = data['Kokborok'].str.lower().tolist()\n",
    "tokenizer_eng.fit_on_texts(all_eng)\n",
    "tokenizer_kok.fit_on_texts(all_kok)\n",
    "\n",
    "# Load pre-trained model (you must have this saved from training phase)\n",
    "try:\n",
    "    model = load_model('kokborok_seq2seq_model.h5')\n",
    "except:\n",
    "    model = None\n",
    "    print(\"Warning: Deep learning model not found, only dictionary/fuzzy matching will be used.\")\n",
    "\n",
    "# Preprocessing function\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    # Handle punctuation including ?, !, ., ,, ;, :, (, )\n",
    "    text = re.sub(r'([.,!?;:()])', r' \\1 ', text)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "    return text.strip().split()\n",
    "\n",
    "# Rule-based Translator\n",
    "def translate_with_dictionary(words):\n",
    "    translated_sentence = []\n",
    "    english_phrases = list(translation_dict.keys())\n",
    "\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        matched = False\n",
    "\n",
    "        if i + 2 < len(words):\n",
    "            trigram = f\"{words[i]} {words[i+1]} {words[i+2]}\"\n",
    "            if trigram in translation_dict:\n",
    "                translated_sentence.append(translation_dict[trigram])\n",
    "                i += 3\n",
    "                matched = True\n",
    "\n",
    "        if not matched and i + 1 < len(words):\n",
    "            bigram = f\"{words[i]} {words[i+1]}\"\n",
    "            if bigram in translation_dict:\n",
    "                translated_sentence.append(translation_dict[bigram])\n",
    "                i += 2\n",
    "                matched = True\n",
    "\n",
    "        if not matched:\n",
    "            word = words[i]\n",
    "            if word in translation_dict:\n",
    "                translated_sentence.append(translation_dict[word])\n",
    "            elif re.match(r'[.,!?;:()]', word):\n",
    "                translated_sentence.append(word)  # keep punctuation\n",
    "            else:\n",
    "                match, score = process.extractOne(word, english_phrases)\n",
    "                if score >= FUZZY_THRESHOLD:\n",
    "                    translated_sentence.append(translation_dict[match])\n",
    "                else:\n",
    "                    translated_sentence.append(f\"[UNK]\")\n",
    "            i += 1\n",
    "\n",
    "    return translated_sentence\n",
    "\n",
    "# Deep Learning Translator\n",
    "def translate_with_model(sentence):\n",
    "    seq = tokenizer_eng.texts_to_sequences([sentence])\n",
    "    seq = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "    prediction = model.predict(seq)\n",
    "    output_seq = np.argmax(prediction, axis=-1)\n",
    "    translated_tokens = tokenizer_kok.sequences_to_texts(output_seq)\n",
    "    return translated_tokens[0]\n",
    "\n",
    "# Main translator\n",
    "def hybrid_translate(sentence):\n",
    "    words = tokenize(sentence)\n",
    "    dict_translation = translate_with_dictionary(words)\n",
    "\n",
    "    unk_count = dict_translation.count(\"[UNK]\")\n",
    "    if model and unk_count > len(words) * 0.3:  # fallback threshold\n",
    "        print(\"[INFO] Fallback to deep learning model.\")\n",
    "        return translate_with_model(sentence)\n",
    "    else:\n",
    "        return ' '.join(dict_translation)\n",
    "\n",
    "# Continuous input loop\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Type 'exit' to quit the translator.\")\n",
    "    while True:\n",
    "        user_input = input(\"\\nEnter an English sentence: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Goodbye! ðŸ‘‹\")\n",
    "            break\n",
    "        kokborok_translation = hybrid_translate(user_input)\n",
    "        print(f\"Kokborok translation: {kokborok_translation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc16cd9-a748-4eb2-b4ca-3dabea0a602d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
